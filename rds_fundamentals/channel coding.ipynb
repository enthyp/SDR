{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ea844275-0c35-4477-ad59-eacd20fd4a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9084fdb3-31cc-4a75-a452-86f77c176964",
   "metadata": {},
   "source": [
    "# Channel coding\n",
    "AKA **forward error correction** (FEC). Adds redundant information to input information so that receiver can detect and correct errors resulting from the noise in the channel.\n",
    "\n",
    "Also used for data storage, e.g. hard drives and CD-ROMs (Reed-Solomon!).\n",
    "\n",
    "### Concepts\n",
    "\n",
    "##### Information\n",
    "\n",
    "(*Telecommunications Breakdown* excellent breakdown)\n",
    "\n",
    "Event occurring (for wireless channels, receiving a given symbol) gives us *information*. The less likely the event, the more information we get. Why? Consider a game of guessing words from a dictionary by their first letters. If you know the word starts with \"k\" it gives you less information, than if you knew it starts with \"x\".\n",
    "\n",
    "We define **amount of information** conveyed by receiving a symbol $x_i$ (observing an outcome of experiment, etc.) as $$I(x_i) = - log(p(x_i))$$ because it's the only function that's additive for independent events and meets other criteria (certain event transfers no information, less likely event transfers more information).\n",
    "\n",
    "For given source alphabet $x = x_i, i = 1, ..., N$ we define **source entropy** as $$H(x) = \\sum_{i=1}^N p(x_i) I(x_i)$$ which is the average (expected) number of bits per symbol. We'd like that as high as possible, we know that $H(x) \\leq log_2(N)$ and maximum is attained for equally likely symbols.\n",
    "\n",
    "##### Channel capacity\n",
    "How many bits per second can we transmit over given channel. Shannon theorem gives an exact upper bound! For given bandwidth $B$ \\[Hz\\] and average signal and noise power $S$ and $N$ \\[W\\]\n",
    "$$C = B \\ log_2 (1 + \\frac{S}{N})$$\n",
    "It illustrates the trade-off between SNR and bandwidth. If we have higher SNR, we can have more bits per symbol - which means lower data rate - which means lower bandwidth. And inversely. Shannon demonstrated that for data rates below $C$ it's always possible to encode data so that it's sent at this rate with arbitrarily small chance of error!\n",
    "\n",
    "You can \"derive\" it intuitively:\n",
    " - max entropy \\[bits/s\\] for $N$ symbols is $log_2(N)$, so when we transmit symbols with period $T$ $$C \\leq \\frac{log_2(N)}{T}$$ \n",
    " - perfect reception requires gaps between symbols larger than noise variation, for real symbols $$\\frac{2 \\sqrt{S + P}}{N - 1} > 2 \\sqrt{P}$$\n",
    " - *Nyquist rate* - max symbol rate that can be transmitted over a channel (not exactly the sampling theorem!), achieved if you transform symbol sequence into continuous signal using sinc pulses (and the more narrow they are, i.e. the more we increase symbol rate, the more bandwidth is occupied) $$\\frac{1}{T} \\leq 2 B$$\n",
    "\n",
    "E.g. for 802.11n WiFi at 2.4 GHz: $B = 20MHz$, for $SNR = 25dB$ we can approximate \n",
    "$$log_2 (1 + \\frac{S}{N}) = \\frac{10 log_{10} (\\frac{S}{N})}{log_{10}(1024)} \\approx \\frac{SNR_{dB}}{3}$$\n",
    "so we get around an upper bound of around 160Mbps per channel. Real rate is probably around half of it due to frame overhead (redundancy in information source), channel coding and modulation not being optimal.\n",
    "\n",
    "##### Code rate\n",
    "Input information to output information ratio. The lower the less efficient code is.\n",
    "\n",
    "# Questions\n",
    "1. If we use lower-order modulation scheme for low SNRs (e.g. QPSK instead of 16QAM), why don't we just increase the magnitude of the symbols to make them more spaced?\n",
    "    - because larger amplitude of transmitted signal = larger required power and we already have established given transmission power and now choose a modulation scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db7a08-5f90-4114-b598-dea31a8408cb",
   "metadata": {},
   "source": [
    "# Linear block codes\n",
    "We assume that symbols are elements of a finite field $F_q$, i.e. messages (codewords) are $m$-length vectors from a vector space over $F_q$. An $(n, \\ k)$ linear code is a $k$-dimensional subspace of this vector space. A *generator matrix* is an $k \\ x \\ n$ matrix whose rows form a basis (linearly independent, span the subspace) for the code subspace. So there are $q^k$ codewords (combinations of basis vectors) and they can be produced by multiplying a $k$-dimensional input by the generator matrix. Every generator matrix can be written in form $[I_n, \\ A]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f6210-4461-4a3b-b8a6-1f2b007b7233",
   "metadata": {},
   "source": [
    "There always exists an $(n-k)$-dimensional subspace that's orthogonal to $C$, i.e. all it's elements are orthogonal to all $C$ elements. It's called the *dual code* for C. It's generator matrix ($(n - k ) \\ x \\ n$) $H$ is called the *parity check matrix* for C and $\\forall_{x \\in C}: \\ H \\ x^T = 0 $.\n",
    "\n",
    "##### Decoding\n",
    "For transmitted codeword $x$ the received codeword is $y = x + z$, where $z$ is the error vector. $s = H y^T = H z^T$ is called the *syndrome*. It doesn't uniquely identify $x$ (nor $z$), there are $q^k$ solutions (of the form $z_0 + x$ for $x \\in C$). So the receiver has the errors narrowed down from $q^n$ to $q^k$ possibilitites. If errors on each symbol occur IID and probability of each erroneous symbol is $\\epsilon \\leq \\frac{1}{q}$, then the solution with smallest Hamming weight (number of non-zero positions) is the most likely error vector.\n",
    "\n",
    "The only problem is to find the minimum Hamming weight solution for given syndrome efficiently. If we precompute these for all syndromes, then we have the fastest decoder possible. \n",
    "\n",
    "Also, for a linear code $C$ if we set $d = min \\{ w_H(c), \\ c \\in C \\}$ (it's the minimum distance between codewords since it's linear subspace), then the above algorithm always finds the correct codeword for error vectors s.t. $2 w_H(z) + 1 \\leq d$. By contradiction, if there was another $y \\in C$ closer to $x + z$, then $$2 w_H(z) + 1 \\leq d = d_H(x, \\ y) \\leq d_H(x, \\ x + z) + d_H(y, \\ x + z) \\leq 2 w_H(z)$$ It can be interpreted as Hamming spheres around the codewords of radius $w_H(z)$ not intersecting.\n",
    "\n",
    "##### Examples - Hamming code\n",
    "Hamming code is a $(7, \\ 4)$ linear block code. It's smallest set of linearly dependent columns of parity-check matrix has 3 elements, so it's capable of correcting 1-bit errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa735b5c-3406-44a3-80e7-24d7d3c69ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 1., 1.],\n",
       "       [0., 1., 0., 0., 1., 0., 1.],\n",
       "       [0., 0., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_gen_matrix = np.hstack([\n",
    "    np.identity(4), \n",
    "    np.array([\n",
    "        [0, 1, 1],\n",
    "        [1, 0, 1],\n",
    "        [1, 1, 0],\n",
    "        [1, 1, 1],\n",
    "    ]),\n",
    "])\n",
    "hamming_gen_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd3af743-dc33-4ec5-9eb9-85dab047bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_parity_check_matrix = np.array([\n",
    "    [0, 1, 1, 1, 1, 0, 0],\n",
    "    [1, 0, 1, 1, 0, 1, 0],\n",
    "    [1, 1, 0, 1, 0, 0, 1],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e4e2b-d566-40a8-969f-9a1e67323007",
   "metadata": {},
   "source": [
    "Hamming code has a nice property w.r.t. decoding, i.e. the syndrome gives us the position where error occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e288203-9091-416b-a028-a6fbb67ea9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n",
      "[1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "def recv_with_error(codeword, err_position, pc_matrix=hamming_parity_check_matrix):\n",
    "    error = np.zeros(7)\n",
    "    error[err_position] = 1\n",
    "    received = (transmitted + error) % 2\n",
    "    syndrome = np.matmul(pc_matrix, received) % 2\n",
    "    print(syndrome)\n",
    "\n",
    "\n",
    "msg = np.array([0, 1, 1, 0])\n",
    "transmitted = np.matmul(msg, hamming_gen_matrix) % 2\n",
    "\n",
    "recv_with_error(transmitted, 3)\n",
    "recv_with_error(transmitted, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f69272-948c-42c7-bd06-844f343c0504",
   "metadata": {},
   "source": [
    "So the syndromes are columns 3 and 1 of parity check matrix, respectively - which points out which position has error in it.\n",
    "\n",
    "**Actually**, it seems that any single-error-detecting code would have that property, just by definition of a syndrome when there's 1 bit of error...\n",
    "\n",
    "But we can make it even cooler. We can verify that matrix below is another parity-check matrix for the Hamming code. And this time a syndrome gives us binary representation of bit number where error occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d9ad5b6-1c49-4b12-b777-87f87d44df80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_parity_check_matrix2 = np.array([\n",
    "    [0, 0, 0, 1, 1, 1, 1],\n",
    "    [0, 1, 1, 0, 0, 1, 1],\n",
    "    [1, 0, 1, 0, 1, 0, 1],\n",
    "])\n",
    "np.matmul(hamming_parity_check_matrix2, np.transpose(hamming_gen_matrix)) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "716c6bf8-bf99-4a2d-a46d-574a0dc9ab4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "recv_with_error(transmitted, 3, pc_matrix=hamming_parity_check_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde16cb-bfc0-4f32-82e3-2c2c93e7fbad",
   "metadata": {},
   "source": [
    "Which is column number 4, position 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294ef068-df38-4361-af9d-4c9469e9cbfd",
   "metadata": {},
   "source": [
    "##### Examples - RDS\n",
    "For RDS a $(26, \\ 16)$ linear code is used, so we have a $(16, \\ 26)$ generator matrix, $(10, \\ 26)$ parity check matrix and our syndromes are 10 bits in length. If this code had no special properties (it's cyclic!), then for each of 1024 syndromes we'd have to find the minimum Hamming weight error vector among 65536 possibilities. It's not a big deal on the computer, perhaps for an integrated circuit that would increase the cost substantially?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be5b2bf-0f6e-4984-a841-9ebbc335c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from error_coding import spec_generator_matrix, spec_parity_check_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43803c87-3b71-47de-86e0-fd2eff33875c",
   "metadata": {},
   "source": [
    "### Summary so far\n",
    " - linear code definition\n",
    " - generator and parity check matrices\n",
    " - syndromes and decoding using minimum Hamming weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac5e74e-2dcf-4ca8-922d-e7bcbc949332",
   "metadata": {},
   "source": [
    "### Linear cyclic block codes\n",
    "A code $C$ is cyclic, if rotation of any codeword produces another codeword.\n",
    "\n",
    "Useful interpretation: for codeword $(C_0, ..., C_n)$ define it's *generating function* as $C(x) = C_0 + C_1 x + ... + C_n x^n$. Then a code is cyclic if for all codewords the codeword defined by generating function $xC(x) \\ (mod \\ x^n - 1))$ is also a codeword (this is the right cyclic shift of $C$!).\n",
    "\n",
    "For a linear cyclic code we define *generator polynomial* (denoted $g(x)$) as the lowest degree polynomial in C. It divides $x^n - 1$ and it also divides all the codewords - and inversely, if it divides a polynomial of degree $\\lt n$, then it's a codeword. Also, any divisor of $x^n - 1$ generates a linear cyclic code.\n",
    "\n",
    "We also define *parity check polynomial* $h(x) = \\frac{x^n - 1}{g(x)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0073ddad-7535-43da-a2c8-59942737d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we identify C_n x^n + ... C_1 x + C_0 = [C_0, ..., C_n] with C_n != 0 unless it's just const 0, then [0]\n",
    "def divide_mod2(dividend, divisor):\n",
    "    assert divisor[-1] != 0 \n",
    "    n = len(dividend)\n",
    "    k = len(divisor)\n",
    "    remainder = dividend.copy()\n",
    "\n",
    "    for i in range(n - 1, k - 2, -1):\n",
    "        if remainder[i] != 0:\n",
    "            for j in range(i, i - k, -1):\n",
    "                # i - j + 1 goes from 1 to k, so k - (i - j + 1) goes from k - 1 to 0\n",
    "                remainder[j] = (remainder[j] - divisor[k - (i - j + 1)]) % 2\n",
    "\n",
    "\n",
    "    # strip potential zero coefficients\n",
    "    non_zero_coef_idx = [i for i in range(0, min(k, n)) if remainder[i] != 0]\n",
    "    return remainder[:non_zero_coef_idx[-1] + 1] if non_zero_coef_idx else [0]\n",
    "\n",
    "\n",
    "def pp(polynomial):\n",
    "    repr = [f'x^{i}' if i > 1 else ('x' if i == 1 else '1') for i in range(len(polynomial)) if polynomial[i] != 0]\n",
    "    print(' + '.join(repr[::-1]) if repr else '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bc1d0781-f916-44b1-aeed-9772b3997e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "hamming_gen_polynomial = [1, 0, 1, 1, 1]  # x^4 + x^3 + x^2 + 1 is the generator for (7, 3) Hamming code, so it divides x^7 - 1\n",
    "pp(divide_mod2([1, 0, 0, 0, 0, 0, 0, 1], hamming_gen_polynomial))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a724d-e4fc-4a76-a08a-67e2f260cc62",
   "metadata": {},
   "source": [
    "It can be shown (Theorem 8.3, corollary 2) that matrices defined as below are the generator and parity check matrices for linear cyclic code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "29945d83-834d-4355-b0d3-4c9648d74f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_matrix(n, generator_polynomial):\n",
    "    k = n - len(generator_polynomial) + 1\n",
    "    gen_m = np.zeros((k, n))\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        # G[i, :] = x^(n - k + i) - x^(n - k + i) (mod g(x))\n",
    "        row = divide_mod2([0] * (n - k + i) + [1], generator_polynomial)\n",
    "        gen_m[i, :len(row)] = row\n",
    "        gen_m[i, n - k + i] = 1\n",
    "\n",
    "    return gen_m\n",
    "\n",
    "\n",
    "def parity_check_matrix(n, generator_polynomial):\n",
    "    k = n - len(generator_polynomial) + 1\n",
    "    pc_m = np.zeros((n - k, n))\n",
    "\n",
    "    for i in range(0, n):\n",
    "        # H[:, i] = x^i (mod g(x))\n",
    "        column = divide_mod2([0] * i + [1], generator_polynomial)\n",
    "        pc_m[:len(column), i] = column\n",
    "\n",
    "    return pc_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b1f28beb-1f67-4f16-8ff2-5cc82f3a0d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_gen_matrix = generator_matrix(7, hamming_gen_polynomial)\n",
    "assert np.all(hamming_gen_matrix == np.array([\n",
    "    [1., 0., 1., 1., 1., 0., 0.],\n",
    "    [1., 1., 1., 0., 0., 1., 0.],\n",
    "    [0., 1., 1., 1., 0., 0., 1.]\n",
    "]))  # from the book\n",
    "\n",
    "hamming_pc_matrix = parity_check_matrix(7, hamming_gen_polynomial)\n",
    "assert np.all(hamming_pc_matrix == np.array([\n",
    "    [1., 0., 0., 0., 1., 1., 0.],\n",
    "    [0., 1., 0., 0., 0., 1., 1.],\n",
    "    [0., 0., 1., 0., 1., 1., 1.],\n",
    "    [0., 0., 0., 1., 1., 0., 1.]\n",
    "]))  # from the book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ed81c7-f41a-4f09-abbd-266ae79a8386",
   "metadata": {},
   "source": [
    "Nice thing about parity check matrix defined this way is that the syndrome $z = H \\ x_0^{T}$ has generating function defined by $r(x) = c_0(x) \\ (mod \\ g(x))$, where $c_0(x)$ is the generating function for the codeword $x_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f9c9259a-cde7-45c1-bee8-f31833e3f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 1, 0])\n",
    "encoded = np.matmul(x, hamming_gen_matrix)\n",
    "error = np.array([0, 0, 1, 0, 1, 0, 0])\n",
    "received = (encoded + error) % 2\n",
    "syndrome = np.matmul(hamming_pc_matrix, received) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a65470f6-0699-4491-b3ff-5ad4c0e82bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x^3 + 1\n"
     ]
    }
   ],
   "source": [
    "pp(syndrome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1ba6e30c-08c9-4ba4-9968-e25608c7773f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x^3 + 1\n"
     ]
    }
   ],
   "source": [
    "pp(divide_mod2(received, hamming_gen_polynomial))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b51edb-2a07-4e07-a191-d8c48880c996",
   "metadata": {},
   "source": [
    "### Summary so far\n",
    " - linear cyclic codes as polynomials\n",
    " - generator and parity check polynomials\n",
    " - generator polynomial completely defines the code\n",
    " - how to form generator and parity check matrices from the generator\n",
    " - how to calculate syndromes with polynomial division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9ed7e2aa-0e48-4137-bf00-2b5d07182006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to go:\n",
    "#  - shifting register encoders for cyclic codes (because they are simple)\n",
    "#  - cyclic Hamming codes - because they have both simple encoders and DECODERS (important)\n",
    "#  - burst-error-trapping decoders for cyclic codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d73e18-c4ea-4f61-bb31-f7e451758b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e820d33-a7a4-45fd-aecd-5b682d502429",
   "metadata": {},
   "source": [
    "# Galois fields\n",
    "We have a set, two operations (\"addition\" and \"multiplication\") and this is an abelian group w.r.t. both operations, plus we have associativity. \n",
    "\n",
    "Basic finite field is $\\mathbb{Z} / p \\mathbb{Z}$, i.e. integers modulo a prime number $p$. The only non-obvious thing here is existence of inverse element for multiplication. It follows from [Bezout's identity](https://en.wikipedia.org/wiki/B%C3%A9zout%27s_identity), because for $n \\in \\mathbb{Z} / p \\mathbb{Z}$ $gcd(n, p) = 1$, so there exist integers $m$ and $k$ such that $k n + m p = gcd(n, p) = 1$, i.e. $k n = 1\\ (mod \\ p)$, so $k$ is the inverse.\n",
    "\n",
    "In general, finite fields can **only** be of order $p^m$, where $p \\in \\mathbb{P}$, $m \\in \\mathbb{Z}$ and they are called Galois fields, denoted $GF(p^m)$. Given a finite field of order $p$ we can **always** select a polynomial $f(x)$ of degree $m$ irreducible over $F_p$ (can't be factorized), define field elements as polynomials of degrees up to $m - 1$ and define all operations $(mod \\ f(x))$, and $GF(p^m)$ arises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8f6264-b3c2-4de9-b950-c35b854d5a86",
   "metadata": {},
   "source": [
    "# Reed-Solomon codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb94b01-0f71-4233-8186-79c002e2afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: really not necessary right now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d23c8ec-5929-47a8-b05a-df38a4691297",
   "metadata": {},
   "source": [
    "# Linear convolutional codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4499861f-f637-4635-b7b9-fc55a93770bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: even less necessary right now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ffb6b9-9b07-4264-88c4-f51da3891f81",
   "metadata": {},
   "source": [
    " - zaczął mając 17 lat\n",
    " - w wieku 20 po 3 latach robił 5.13+ (5.13d/5.14a Galaxy Emperor, 8b/+) wspinając się głównie po sportach\n",
    " - 2020 5.12+ Moonlight Buttress OS (po 3 latach?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b279e346-18c2-41d5-b045-7159da153282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
